import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
import re
import warnings
warnings.filterwarnings('ignore')
sb.set_style("darkgrid")
from underthesea import word_tokenize, pos_tag, sent_tokenize # sent_tokenize t√°ch ra t·ª´ 1 vƒÉn b·∫£n th√†nh nhi·ªÅu c√¢u
import regex
import demoji
from pyvi import ViPosTagger, ViTokenizer
import string
from sklearn.model_selection import KFold, train_test_split, cross_validate
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer
from imblearn.over_sampling import RandomOverSampler, SMOTE
from sklearn.preprocessing import FunctionTransformer
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.semi_supervised import LabelSpreading
from sklearn.metrics import f1_score
from imblearn.pipeline import Pipeline
import os
from imblearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.naive_bayes import MultinomialNB,ComplementNB, GaussianNB
from sklearn.svm import SVC, LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier


from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import time

import joblib
import streamlit  as st


data = pd.read_csv('crawl_data/Foody.csv')



############
def replace_word(text):
    text = text.lower()  #chuy·ªÉn k√≠ t·ª± in hoa sang ch·ªØ th∆∞·ªùng
    
    text = text.replace('\.',' ') #b·ªè m·ªôt s·ªë k√≠ t·ª± ƒë·∫∑c bi·ªát ngƒÉn c√°ch c√¢u
    text = text.replace(',',' ') #b·ªè m·ªôt s·ªë k√≠ t·ª± ƒë·∫∑c bi·ªát ngƒÉn c√°ch c√¢u
    text = text.replace('[0-9]+k|[0-9]+ƒë|[0-9]+vnd||[0-9]+vnƒë','') #b·ªè c√°c c·ª•m v·ªÅ gi√° 
    text = text.replace( ':)','')
    text = text.replace( 'ü•∞',' y√™u ')
    text = text.replace( 'üòò',' y√™u ')
    text = text.replace( 'app','')
    text = text.replace( ' add ',' th√™m ')
    text = text.replace( 'tuy·ªát v∆°i','tuy·ªát v·ªùi')
    text = text.replace( 'tuy√™th v·ªùi','tuy·ªát v·ªùi')
    text = text.replace( 'soang ch·∫£nh','sang ch·∫£nh')
    text = text.replace( 'ch√¨nh √¨nh','ch√¨nh_√¨nh')
    text = text.replace( ' √¨nh ',' m√¨nh ')
    text = text.replace( ' tuy·ªá ',' tuy·ªát ')
    text = text.replace(' kb ',' kh√¥ng bi·∫øt ')
    text = text.replace('b√°h','b√°nh')
    text = text.replace(' k h·ªÅ ',' kh√¥ng h·ªÅ ')
    text = text.replace('ƒë∆∞pj','ƒë·∫πp')
    text = text.replace('r·∫ªe','r·∫ª')
    text = text.replace(' siu ',' si√™u ')
    text = text.replace(' ∆∞g ',' ∆∞ng ')
    text = text.replace(' b√¥g ',' b√¥ng ')
    text = text.replace(' u·ªëg ',' u·ªëng ')
    text = text.replace(' m√¨h ',' m√¨nh ')
    text = text.replace(' rat ',' r·∫•t ')
    text = text.replace('r√¢dt','r·∫•t')
    text = text.replace('rata','r·∫•t')
    text = text.replace('dim·ªõium','m·ªõi')
    text = text.replace(' nhuet65 ',' nhi·ªát ')
    text = text.replace(' m·ª≥ ',' m√¨ ')
    text = text.replace(' cmt ',' b√¨nh lu·∫≠n ')
    text = text.replace(' rv ',' nh·∫≠n x√©t ')
    text = text.replace(' t ',' tao ')
    text = text.replace(' chea ',' ch∆∞a ')
    text = text.replace(' ngonn ',' ngon ')
    text = text.replace(' qay ',' quay ')
    text = text.replace(' fa·ªâ ',' ph·∫£i ')
    text = text.replace(' it ',' √≠t ')
    text = text.replace(' th√†h ',' th√†nh ')
    text = text.replace(' nnhaf ',' nh√† ')
    text = text.replace(' nhi√™ud ',' nhi·ªÅu ')
    text = text.replace('v·ªçmg','v·ªçng')
    text = text.replace(' nc ',' n∆∞·ªõc ')
    text = text.replace(' nuoc ',' n∆∞·ªõc ')
    text = text.replace(' n∆∞∆°c ',' n∆∞·ªõc ')
    text = text.replace(' ma91m ',' m·∫Øm ')
    text = text.replace(' muon1 ',' mu·ªën ')
    text = text.replace(' mu√≥in ',' mu·ªën ')
    text = text.replace('deliverynow','')
    text = text.replace(' foody ',' ')
    text = text.replace(' grab ',' ')  
    text = text.replace(' baemin ',' ')    
    text = text.replace(' gojek ',' ')
    text = text.replace(' sale ',' ')
    text = text.replace(' fresh ',' s·∫°ch ')
    text = text.replace('tƒë·ªô','th√°i ƒë·ªô')
    text = text.replace('th√°i ƒë√¥','th√°i ƒë·ªô')
    text = text.replace(' √∫n ',' u·ªëng ')
    text = text.replace(' ƒÉm ',' ƒÉn ')
    text = text.replace(' ro√†ii ',' r·ªìi ')
    text = text.replace(' ƒë√¥g ',' ƒë√¥ng ')
    text = text.replace(' c≈©g ',' c≈©ng ')
    text = text.replace(' t∆°i ',' h∆°i ')
    text = text.replace(' m·ª•t ',' m·ªôt ')
    text = text.replace(' ok.',' ƒë∆∞·ª£c.')
    text = text.replace(' chut ',' ch√∫t ')
    text = text.replace('th√≠c h·ª£p','th√≠ch h·ª£p')
    text = text.replace('d√™c th∆∞∆°ng','d·ªÖ th∆∞∆°ng')
    text = text.replace(' ai nƒÉ ',' ai ƒÉn ')
    text = text.replace(' an v√†o lai ',' ƒÉn v√†o l·∫°i ')
    text = text.replace(' an ngon ',' ƒÉn ngon ')
    text = text.replace(' m·ªçi nguoi ',' m·ªçi ng∆∞·ªùi ')
    text = text.replace(' mieng thit ',' mi·∫øng th·ªãt ')
    text = text.replace(' tranht h·ªß ',' tranh th·ªß ')
    text = text.replace(' m√£ km ',' m√£ khuy·∫øn m√£i ')
    text = text.replace(' ∆°i k√¨ ',' h∆°i k√¨ ')
    text = text.replace(' nh√† h√†g ',' nh√† h√†ng ')
    text = text.replace(' h·ª£p l√∫ ',' h·ª£p l√Ω ')
    text = text.replace(' l·∫ßm li ',' l·∫ßm l√¨ ')
    text = text.replace(' fai b√†n ',' ph·∫£i b√†n ')
    text = text.replace(' decor ',' trang tr√≠ ')
    text = text.replace(' decoration ',' trang tr√≠ ')
    text = text.replace(' l√¢n ch√†o ',' l·∫ßn n√†o ')
    text = text.replace('th√¢n thi·ªá','th√¢n thi·ªán')
    text = text.replace('delivery','')
    text = text.replace('amateur','nghi·ªáp d∆∞')
    text = text.replace('must try','ph·∫£i th·ª≠')
    text = text.replace('must-try','ph·∫£i th·ª≠')
    text = text.replace('g√≤nn·∫øu',' g√≤n n·∫øu')
    text = text.replace('t√≠h $','t√≠nh ti·ªÅn')
    text = text.replace('1 ƒëi','m·ªôt ƒëi')
    text = text.replace(' m√≥n an ',' m√≥n ƒÉn ')
    text = text.replace(' qu√° t·∫∑ng ',' qu√°n t·∫∑ng ')
    text = text.replace('h·ª£p l√≠','h·ª£p l√Ω')
    text = text.replace('ph·ª•c v·ª• t√™','ph·ª•c v·ª• t·ªá')
    text = text.replace('k nh·ªõ','kh√¥ng nh·ªõ')
    text = text.replace('ko gian','kh√¥ng gian')
    text = text.replace('kh√¥ng gi√°n','kh√¥ng gian')
    text = text.replace('ch·∫•t l∆∞∆°ng','ch·∫•t l∆∞·ª£ng')
    text = text.replace(' soeeu ngon ',' si√™u ngon ')
    text = text.replace('t√¥n ti·ªÅn','t·ªën ti·ªÅn')
    text = text.replace('b√© ch·ªó n√†y','n√© ch·ªó n√†y')
    text = text.replace('gi√° ph·∫£i chƒÉng','gi√° h·ª£p l√Ω')
    text = text.replace('gi√° c·∫£ ph·∫£i chƒÉng','gi√° c·∫£ h·ª£p l√Ω')
    text = text.replace('ng·ªçn ƒë·∫πp m·∫Øt','ngon ƒë·∫πp m·∫Øt')
    text = text.replace('ko bao h','kh√¥ng bao gi·ªù')
    text = text.replace(' kb√¢y gi·ªù ',' kh√¥ng bao gi·ªù ')
    text = text.replace('#kh√¥ngbaogioquaylai','kh√¥ng bao gi·ªù quay l·∫°i')
    text = text.replace('khongbaogioquaylai','kh√¥ng bao gi·ªù quay l·∫°i')

    
    text = text.replace(r'(\w)\1*',r'\1') #thay th·∫ø nh·ªØng t·ª´ l·∫∑p ƒëi l·∫∑p l·∫°i nh∆∞ wowwwww => wow
    text = text.replace(r'\b[kk]+\b',' t·ªët ') # √≠t nh·∫•t 2 ch·ªØ kk li√™n t·ª•c ƒë·ªïi th√†nh t·ªët
    text = text.replace('[^a-z√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë]',' ')
    text = text.replace(' [a-z√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë]{1} ',' ')
    khong = [' khg ', ' k ',' ko ', ' k0 ', ' kog ', ' ƒë√©o ', ' ƒë·∫øch ', ' n·ªè ', ' not ', ' kg ', ' kh√¥g ' , ' hok ', ' h√¥ng ', ' k√¥ ', ' ch·∫≥ng ', ' ch·∫≥g ', ' kh·ªèi ', ' kh ', ' hong ', ' doesn t ', ' don t ', ' khong ']
    for c in khong:
        text = text.replace(c,' kh√¥ng ')
    
    tot = [' g√∫t ', ' good ', ' gud ', ' nice ', ' nicely ', ' perfect ', ' perfectly ']
    for c in tot:
        text = text.replace(c,' t·ªët ')
    
    dc = [' ƒëc ', ' dc ', ' dk ', ' ƒëk ', ' dx ', ' ƒëx ',  ' duoc ',' okie ', ' okey ', ' √¥ k√™ ', ' oke ', ' okay ', 'ok', ' oki ']
    for c in dc:
        text = text.replace(c,' ƒë∆∞·ª£c ')
    
    thich = ['like', ' thik ', ' thix ', ' thjk ', ' thich ']
    for c in thich:
        text = text.replace(c,' th√≠ch ')
    
    bthg = [' bt ', ' bth ', ' bthg ']
    for c in bthg:
        text = text.replace(c,' b√¨nh th∆∞·ªùng ')
    
    ngon = [' mlem ', ' yummy ', ' nhon ', ' ngol ', ' delicious ', ' tasty ', ' wao ', ' w√†o ', ' wow ']
    for c in ngon:
        text = text.replace(c,' ngon ')
    
    order = [' book ', 'order', ' ord ', ' od ' , ' oder ']
    for c in order:
        text = text.replace(c,' ƒë·∫∑t ')
    
    roi = [' r ', ' roi ', ' ro√†i ', ' r√≤i ']
    for c in roi:
        text = text.replace(c,' r·ªìi ')
    
    thanks = [' tks ', ' thanks ', ' thank ', ' tanks ', ' tk ']
    for c in thanks:
        text = text.replace(c,' c·∫£m ∆°n ')
    
    biet = [' bik ', ' b√≠k ', ' pjk ', ' pik ']
    for c in biet:
        text = text.replace(c,' bi·∫øt ')
    
    minh = [' m ', ' mik ']
    for  c in minh:
        text = text.replace(c,' m√¨nh ')
    
    qua = [' q√° ', ' w√° ']
    for  c in qua:
        text = text.replace(c,' qu√° ')
    
    cuoi = [' ha ha ', ' haha ', ' he he ', ' hehe ', ' hi hi ', ' hihi ', ' hj hj ', ' hjhj ', ' h√™h ', ' c∆∞·ªùi ', ' cheers ', ' hihi ']
    for  c in cuoi:
        text = text.replace(c,' c∆∞·ªùi ')
    
    te = [' shit ', ' cc ', ' sad ', ' poor ', ' worst ', ' disapointed ', ' tasteless ', ' disgusted ', ' bad ', ' fucking ']
    for  c in te:
        text = text.replace(c,' t·ªá ')
    
    dat = [' expensive ', ' m·∫Øc ', ' overpriced ', ' overpirced ']
    for  c in dat:
        text = text.replace(c,' ƒë·∫Øt ')
    
    nv = [' nv ', ' nvien ', ' n.vi√™n ']
    for c in nv:
        text = text.replace(c,' nh√¢n vi√™n ')
    
    cheap = [' cheap ', ' g·∫ª ', ' gh·∫ª ']
    for c in cheap:
        text = text.replace(c,' r·∫ª ')
    
    xs = [' fantastic ', ' excelent ', ' x√∫c x·∫Øc ', ' xu·∫•t s·∫Øccc ']
    for c in xs:
        text = text.replace(c,' xu·∫•t_s·∫Øc ')
    
    rude = [' impolite ', ' rude ', ' l√°o ', ' m·∫•t d·∫°y ', ' h·ªón x∆∞·ª£c ', ' th√¥ l·ªó ']
    for c in rude:
        text = text.replace(c,' b·∫•t l·ªãch s·ª± ')
    
    pv = [' pv ', ' pvu ']
    for c in pv:
        text = text.replace(c,' ph·ª•c v·ª• ')
    
    cmt = [' cmmt ', ' cmt ', ' comment ']
    for c in cmt:
        text = text.replace(c,' b√¨nh lu·∫≠n ')
    
    truoc_day = [' tr∆∞·ªõc kia ', ' tr∆∞·ªõc ƒë√≥ ']
    for c in truoc_day:
        text = text.replace(c,' tr∆∞·ªõc ƒë√¢y ')
        
    
    
    ### --- ƒê·ªïi 15k, 75k,... th√†nh 15000, 75000,....
    # H√†m thay th·∫ø ƒë·ªÉ chuy·ªÉn "k" th√†nh "000" v√† chuy·ªÉn chu·ªói th√†nh s·ªë nguy√™n
    def replace_with_thousands(match):
        return str(int(match.group(1)) * 1000)
    
    # Thay th·∫ø "k" b·∫±ng "000" v√† chuy·ªÉn chu·ªói th√†nh s·ªë nguy√™n
    text = re.sub(r'(\d+)k', replace_with_thousands, text)
    
    
    
    # Bi·ªÉu th·ª©c ch√≠nh quy ƒë·ªÉ b·ªè c√°c ch·ªØ c√°i k√©o d√†i
    # H√†m thay th·∫ø ƒë·ªÉ gi·ªØ l·∫°i ch·ªØ c√°i ƒë·∫ßu ti√™n v√† lo·∫°i b·ªè c√°c ch·ªØ c√°i k√©o d√†i
    def remove_repeated_letters(match):
        return match.group(1)
    
    # Thay th·∫ø c√°c ch·ªØ c√°i k√©o d√†i b·∫±ng c√°c ch·ªØ c√°i duy nh·∫•t
    text = re.sub(r'(\w)(\1{2,})', remove_repeated_letters, text)
    
    
    replace_list = {' ship ': ' giao h√†ng ', ' fody ': ' ·ª©ng d·ª•ng ',' tl ':' tr·∫£ l·ªùi ',' r ':' r·ªìi ','vs':'v·ªõi','tr·ªÉ':'tr·ªÖ','bh':'b√¢y gi·ªù',' ntn ':' nh∆∞ th·∫ø n√†y ',
                     'ms':'m·ªõi', ' hnay ':' h√¥m nay ', 'mn':'m·ªçi ng∆∞·ªùi', 'd·∫≠y':'v·∫≠y',' dzay ':' v·∫≠y ',' wa ':' qua ', ' zui ':' vui ',' kbh ':' kh√¥ng bao gi·ªù ',
                     'nx':'nh·∫≠n x√©t', ' dj ':' ƒëi ', ' r√πi ':' r·ªìi ',' view ':' phong c·∫£nh ','cx':'c≈©ng',' kbiet ':' kh√¥ng bi·∫øt ', ' review ':' nh·∫≠n x√©t',
                    ' trc ':' tr∆∞·ªõc ', ' bil ': ' h√≥a ƒë∆°n', ' shiper ' : ' ng∆∞·ªùi v·∫≠n chuy·ªÉn ', 'shipper': 'ng∆∞·ªùi v·∫≠n chuy·ªÉn'  ,'check in': '', 'checkin':'',
                   'chick in':'', ' c ': ' ch·ªã ', ' t ': ' t√¥i ', ' a ':' anh ', ' j ': ' g√¨ ', ' m√∫n ': ' mu·ªën ', ' ngag ': ' ngang ', ' ak ': ' √† ',
                   ' complain ': ' ph√†n n√†n ', ' free ': ' mi·ªÖn ph√≠ ', ' free.': ' mi·ªÖn ph√≠.', ' ph·ªù ri ': ' mi·ªÖn ph√≠ ' ,' recommend ': ' ƒë·ªÅ xu·∫•t ', 
                    ' c√πg ': ' c√πng ', ' nh∆∞g ': ' nh∆∞ng ', 'qua loa': 's∆° s√†i', 'x∆° s√†i': 's∆° s√†i','s∆° x√†i': 's∆° s√†i', ' never ': ' kh√¥ng bao gi·ªù ',
                    ' service ': ' ph·ª•c v·ª• ', 'vui v·∫Ω': 'vui v·∫ª', ' <3 ': ' y√™u ', 'nghƒ© d∆∞·ª°ng': 'ngh·ªâ d∆∞·ª°ng', 'trung b√¨ng': 'trung b√¨nh', 
                    'b·ªó duong': 'b·ªï d∆∞·ª°ng', 'ƒë·∫•t m·∫•t': 'ƒë·∫πp m·∫Øt', 'nice': 't·ªët', ' soeeu ƒë·ªânh ': ' si√™u ƒë·ªânh ', 'th√¢n thi·ªánn': 'th√¢n thi·ªán',
                    'quay l·∫°i': 'tr·ªü l·∫°i', 'gh√© l·∫°i': 'tr·ªü l·∫°i', 'th·∫Øc ƒë·∫Øt': 'th·∫Øc m·∫Øc', ' c·ªßg ': ' c·ªßng ', ' take care ' : ' chƒÉm s√≥c ',
                    'r·∫•t l√†': 'r·∫•t', 'qu√° l√†': 'qu√°', ' r√≤n ' : ' gi√≤n ', 'welcome': 'ch√†o ƒë√≥n', 'tiet kiem': 'ti·∫øt ki·ªám', ' si√™u ': ' r·∫•t ',
                    ' c·ªëc ': ' ly ', 't√≠ hon': 'nh·ªè', ' kute ': ' d·ªÖ th∆∞∆°ng ', ' cute ': ' d·ªÖ th∆∞∆°ng ', ' best ': ' tuy·ªát v·ªùi ', 'very bad' : 'r·∫•t t·ªá',
                    'come back': 'tr·ªü l·∫°i', 'sang ch·∫£nh': 'sang tr·ªçng', 'kh√¥ng qu√°': 'b√¨nh th∆∞·ªùng', 'r·∫•t ch·∫•t l∆∞·ª£ng': 'r·∫•t ngon', 'qu√° ch·∫•t l∆∞·ª£ng': 'qu√° ngon',
                    'nogn': 'ngon', 'th·∫°m t·ªá': 'th·∫≠m t·ªá', 'c√¥ng t√∫a': 'c√¥ng ch√∫a', 'kh√¥ng b·ªã': 'kh√¥ng', 'kh√¥ng ƒë∆∞·ª£c': 'kh√¥ng', 'service': 'ph·ª•c v·ª•', 'x·ª©c x·∫Øc': 'xu·∫•t s·∫Øc',
                    'super': 'r·∫•t', 'kh√¥ng th·∫•y ch√°n': 'kh√¥ng ch√°n', 'kh√¥ng th·∫•y ngon': 'kh√¥ng ngon', 'kh√¥ng th·∫•y no': 'kh√¥ng no', 'kh√¥ng th·∫•y ng√°n': 'kh√¥ng ng√°n',
                    'ngon c·ª±c k√¨': 'r·∫•t ngon', 'c·ª±c k√¨ ngon': 'r·∫•t ngon', 'si√™u ngon': 'r·∫•t ngon', 'c·ª±c d·ªü': 'r·∫•t d·ªü', 'si√™u d·ªü': 'r·∫•t d·ªü', 'd·ªü c·ª±c k√¨': 'r·∫•t d·ªü',
                    'si√™u ch√°n': 'r·∫•t ch√°n', 'c·ª±c ch√°n': 'r·∫•t ch√°n', 'ngon c·ª±c': 'r·∫•t ngon', 'c·ª±c k√¨ t·ªá': 'r·∫•t t·ªá', 'c·ª±c t·ªá': 'r·∫•t t·ªá', 'c·ª±c ngon': 'r·∫•t ngon',
                    'kh√¥ng bao gi·ªù': 'kh√¥ng', 'thi·∫øu chuy√™n nghi·ªáp': 'kh√¥ng chuy√™n nghi·ªáp',
                    }
    
    for word, rep_word in replace_list.items():
      text = text.replace(word,rep_word)
    
    
    text = text.replace(r'(\s)\1*',r'\1') #thay th·∫ø nh·ªØng kho·∫£ng tr·∫Øng l·∫∑p l·∫°i
    return text

#add columns review_class:
data['review_class'] = ['positive' if a >= 8 else 'negative' if a < 5 else 'neural' for a in data.ratings]
#label encoder:
data['review_class_num'] = [0 if x == 'positive'  else 1 if x == 'neural' else 2 for x in data.review_class]

##LOAD EMOJICON
file = open('data/files/emojicon.txt', 'r', encoding="utf8")
emoji_lst = file.read().split('\n')
emoji_dict = {}
for line in emoji_lst:
    key, value = line.split('\t')
    emoji_dict[key] = str(" "+value)
file.close()
#################
#LOAD TEENCODE
file = open('data/files/teencode.txt', 'r', encoding="utf8")
teen_lst = file.read().split('\n')
teen_dict = {}
for line in teen_lst:
    key, value = line.split('\t')
    teen_dict[key] = str(value)
file.close()
###############
#LOAD TRANSLATE ENGLISH -> VNMESE
file = open('data/files/english-vnmese.txt', 'r', encoding="utf8")
english_lst = file.read().split('\n')
english_dict = {}
for line in english_lst:
    key, value = line.split('\t')
    english_dict[key] = str(value)
file.close()
################
#LOAD wrong words
file = open('data/files/wrong-word.txt', 'r', encoding="utf8")
wrong_lst = file.read().split('\n')
file.close()
#################
#LOAD STOPWORDS
file = open('data/files/vietnamese-stopwords.txt', 'r', encoding="utf8")
stopwords_lst = file.read().split('\n')
file.close()

def process_text(text, emoji_dict, teen_dict, wrong_lst):
# def process_text(text, emoji_dict, teen_dict):
    document = text.lower()
    document = document.replace("‚Äô",'')
    document = regex.sub(r'\.+', ".", document)
    new_sentence =''
    for sentence in sent_tokenize(document):
        # if not(sentence.isascii()):
        ###### CONVERT EMOJICON
        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))
        ###### CONVERT TEENCODE
        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())
        ###### DEL Punctuation & Numbers
        pattern = r'(?i)\b[a-z√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë]+\b'
        sentence = ' '.join(regex.findall(pattern,sentence))
        ###### DEL wrong words   
        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())
        ###### english words  
        # sentence = ' '.join(word if word not in dict_eng_vn.keys() else dict_eng_vn[word] for word in sentence.split())
        new_sentence = new_sentence+ sentence + '. '                    
    document = new_sentence  
    #print(document)
    ###### DEL excess blank space
    document = regex.sub(r'\s+', ' ', document).strip()
    return document

# Chu·∫©n h√≥a unicode ti·∫øng vi·ªát
def loaddicchar():
    uniChars = "√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªáƒë√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜƒê√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥√ÇƒÇƒê√î∆†∆Ø"
    unsignChars = "aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU"

    dic = {}
    char1252 = 'aÃÄ|aÃÅ|aÃâ|aÃÉ|aÃ£|√¢ÃÄ|√¢ÃÅ|√¢Ãâ|√¢ÃÉ|√¢Ã£|ƒÉÃÄ|ƒÉÃÅ|ƒÉÃâ|ƒÉÃÉ|ƒÉÃ£|eÃÄ|eÃÅ|eÃâ|eÃÉ|eÃ£|√™ÃÄ|√™ÃÅ|√™Ãâ|√™ÃÉ|√™Ã£|iÃÄ|iÃÅ|iÃâ|iÃÉ|iÃ£|oÃÄ|oÃÅ|oÃâ|oÃÉ|oÃ£|√¥ÃÄ|√¥ÃÅ|√¥Ãâ|√¥ÃÉ|√¥Ã£|∆°ÃÄ|∆°ÃÅ|∆°Ãâ|∆°ÃÉ|∆°Ã£|uÃÄ|uÃÅ|uÃâ|uÃÉ|uÃ£|∆∞ÃÄ|∆∞ÃÅ|∆∞Ãâ|∆∞ÃÉ|∆∞Ã£|yÃÄ|yÃÅ|yÃâ|yÃÉ|yÃ£|AÃÄ|AÃÅ|AÃâ|AÃÉ|AÃ£|√ÇÃÄ|√ÇÃÅ|√ÇÃâ|√ÇÃÉ|√ÇÃ£|ƒÇÃÄ|ƒÇÃÅ|ƒÇÃâ|ƒÇÃÉ|ƒÇÃ£|EÃÄ|EÃÅ|EÃâ|EÃÉ|EÃ£|√äÃÄ|√äÃÅ|√äÃâ|√äÃÉ|√äÃ£|IÃÄ|IÃÅ|IÃâ|IÃÉ|IÃ£|OÃÄ|OÃÅ|OÃâ|OÃÉ|OÃ£|√îÃÄ|√îÃÅ|√îÃâ|√îÃÉ|√îÃ£|∆†ÃÄ|∆†ÃÅ|∆†Ãâ|∆†ÃÉ|∆†Ã£|UÃÄ|UÃÅ|UÃâ|UÃÉ|UÃ£|∆ØÃÄ|∆ØÃÅ|∆ØÃâ|∆ØÃÉ|∆ØÃ£|YÃÄ|YÃÅ|YÃâ|YÃÉ|YÃ£'.split(
        '|')
    charutf8 = "√†|√°|·∫£|√£|·∫°|·∫ß|·∫•|·∫©|·∫´|·∫≠|·∫±|·∫Ø|·∫≥|·∫µ|·∫∑|√®|√©|·∫ª|·∫Ω|·∫π|·ªÅ|·∫ø|·ªÉ|·ªÖ|·ªá|√¨|√≠|·ªâ|ƒ©|·ªã|√≤|√≥|·ªè|√µ|·ªç|·ªì|·ªë|·ªï|·ªó|·ªô|·ªù|·ªõ|·ªü|·ª°|·ª£|√π|√∫|·ªß|≈©|·ª•|·ª´|·ª©|·ª≠|·ªØ|·ª±|·ª≥|√Ω|·ª∑|·ªπ|·ªµ|√Ä|√Å|·∫¢|√É|·∫†|·∫¶|·∫§|·∫®|·∫™|·∫¨|·∫∞|·∫Æ|·∫≤|·∫¥|·∫∂|√à|√â|·∫∫|·∫º|·∫∏|·ªÄ|·∫æ|·ªÇ|·ªÑ|·ªÜ|√å|√ç|·ªà|ƒ®|·ªä|√í|√ì|·ªé|√ï|·ªå|·ªí|·ªê|·ªî|·ªñ|·ªò|·ªú|·ªö|·ªû|·ª†|·ª¢|√ô|√ö|·ª¶|≈®|·ª§|·ª™|·ª®|·ª¨|·ªÆ|·ª∞|·ª≤|√ù|·ª∂|·ª∏|·ª¥".split(
        '|')
    for i in range(len(char1252)):
        dic[char1252[i]] = charutf8[i]
    return dic
 
# ƒê∆∞a to√†n b·ªô d·ªØ li·ªáu qua h√†m n√†y ƒë·ªÉ chu·∫©n h√≥a l·∫°i
def convert_unicode(txt):
    dicchar = loaddicchar()
    return regex.sub(
        r'aÃÄ|aÃÅ|aÃâ|aÃÉ|aÃ£|√¢ÃÄ|√¢ÃÅ|√¢Ãâ|√¢ÃÉ|√¢Ã£|ƒÉÃÄ|ƒÉÃÅ|ƒÉÃâ|ƒÉÃÉ|ƒÉÃ£|eÃÄ|eÃÅ|eÃâ|eÃÉ|eÃ£|√™ÃÄ|√™ÃÅ|√™Ãâ|√™ÃÉ|√™Ã£|iÃÄ|iÃÅ|iÃâ|iÃÉ|iÃ£|oÃÄ|oÃÅ|oÃâ|oÃÉ|oÃ£|√¥ÃÄ|√¥ÃÅ|√¥Ãâ|√¥ÃÉ|√¥Ã£|∆°ÃÄ|∆°ÃÅ|∆°Ãâ|∆°ÃÉ|∆°Ã£|uÃÄ|uÃÅ|uÃâ|uÃÉ|uÃ£|∆∞ÃÄ|∆∞ÃÅ|∆∞Ãâ|∆∞ÃÉ|∆∞Ã£|yÃÄ|yÃÅ|yÃâ|yÃÉ|yÃ£|AÃÄ|AÃÅ|AÃâ|AÃÉ|AÃ£|√ÇÃÄ|√ÇÃÅ|√ÇÃâ|√ÇÃÉ|√ÇÃ£|ƒÇÃÄ|ƒÇÃÅ|ƒÇÃâ|ƒÇÃÉ|ƒÇÃ£|EÃÄ|EÃÅ|EÃâ|EÃÉ|EÃ£|√äÃÄ|√äÃÅ|√äÃâ|√äÃÉ|√äÃ£|IÃÄ|IÃÅ|IÃâ|IÃÉ|IÃ£|OÃÄ|OÃÅ|OÃâ|OÃÉ|OÃ£|√îÃÄ|√îÃÅ|√îÃâ|√îÃÉ|√îÃ£|∆†ÃÄ|∆†ÃÅ|∆†Ãâ|∆†ÃÉ|∆†Ã£|UÃÄ|UÃÅ|UÃâ|UÃÉ|UÃ£|∆ØÃÄ|∆ØÃÅ|∆ØÃâ|∆ØÃÉ|∆ØÃ£|YÃÄ|YÃÅ|YÃâ|YÃÉ|YÃ£',
        lambda x: dicchar[x.group()], txt)

# c√≥ th·ªÉ b·ªï sung th√™m c√°c t·ª´: ch·∫≥ng, ch·∫£...
def process_special_word(text):
    new_text = ''
    text_lst = text.split()
    i= 0
    if 'kh√¥ng' in text_lst or 'r·∫•t' in text_lst or 'qu√°' in text_lst:
        while i <= len(text_lst) - 1:
            word = text_lst[i]
            #print(word)
            #print(i)
            if  word == 'kh√¥ng' or word == 'r·∫•t' or  word == 'qu√°':
                next_idx = i+1
                if next_idx <= len(text_lst) -1:
                    word = word +'_'+ text_lst[next_idx]
                i= next_idx + 1
            else:
                i = i+1
            new_text = new_text + word + ' '
    else:
        new_text = text
    return new_text.strip()

def process_postag_thesea(text):
    new_document = ''
    for sentence in sent_tokenize(text):
        sentence = sentence.replace('.','')
        ###### POS tag
        lst_word_type = ['A','AB','V','VB','VY','R', 'M', 'N', 'C']
        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format="text"))))
        new_document = new_document + sentence + ' '
    ###### DEL excess blank space
    new_document = regex.sub(r'\s+', ' ', new_document).strip()
    return new_document

def remove_stopword(text, stopwords):

    ###### REMOVE stop words
    document = ' '.join('' if word in stopwords else word for word in text.split())
    #print(document)
    ###### DEL excess blank space
    document = re.sub(r'\s+', ' ', document).strip()
    return document

from sql_utils import save_to_database
df_new = pd.read_csv("Labeled_Foody_Review_from_model.csv")
df_new = df_new.dropna()

X_train, X_test, Y_train, Y_test = train_test_split(df_new['processed_comments'], df_new['review_class_num'], test_size=0.2)

model = joblib.load('model.joblib')
Y_pred = model.predict(X_test)

### Show k·∫øt qu·∫£ l√™n Streamlit
menu = ["Gi·ªõi thi·ªáu"]
choice = st.sidebar.selectbox('Menu', menu)


st.subheader("Gi·ªõi thi·ªáu")
st.write("""
    H·ªá th·ªëng ph√¢n lo·∫°i c√°c ph·∫£n h·ªìi c·ªßa kh√°ch h√†ng th√†nh 3 nh√≥m: t√≠ch c·ª±c, ti√™u c·ª±c v√† trung l·∫≠p. D·ª±a tr√™n d·ªØ li·ªáu d·∫°ng vƒÉn b·∫£n.
    X√¢y d·ª±ng h·ªá th·ªëng d·ª±a tr√™n l·ªãch s·ª≠ nh·ªØng ƒë√°nh gi√° c·ªßa c√°c kh√°ch h√†ng ƒë√£ c√≥ tr∆∞·ªõc ƒë√≥, d·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p t·ª´ ph·∫ßn b√¨nh lu·∫≠n v√† ƒë√°nh gi√° c·ªßa kh√°ch h√†ng ·ªü trang Foody‚Ä¶
""")


with st.form("my_form"):
    st.write("""
    M√¥ h√¨nh hi·ªán t·∫°i v·∫´n c√≤n ch∆∞a th·ª±c s·ª± ho√†n thi·ªán. Nh·ªØng b√¨nh lu·∫≠n c·ªßa b·∫°n s·∫Ω l√† ngu·ªìn d·ªØ li·ªáu qu√Ω gi√° gi√∫p c·∫£i thi·ªán kh·∫£ nƒÉng d·ª± ƒëo√°n.
    C·∫£m ∆°n r·∫•t nhi·ªÅu!!!
""")
    st.write('#### Nh·∫≠p b√¨nh lu·∫≠n c·ªßa b·∫°n')
    comment = st.text_input("Nh·∫≠p b√¨nh lu·∫≠n: ")
    # review = st.selectbox("B·∫°n mu·ªën: ", options = ["B√¨nh lu·∫≠n t√≠ch c·ª±c", "B√¨nh lu·∫≠n trung l·∫≠p", "B√¨nh lu·∫≠n ti√™u c·ª±c"])
    submit = st.form_submit_button(label='Submit')

    if submit:  # X·ª≠ l√Ω khi nh·∫•n n√∫t "Submit"
        # Th·ª±c hi·ªán x·ª≠ l√Ω khi nh·∫•n "Submit"
        if comment:
            text = comment
            document = replace_word(text)
            document = process_text(document, emoji_dict, teen_dict, wrong_lst)
            document = convert_unicode(document)
            document = process_postag_thesea(document)
            # document
            document = remove_stopword(document,stopwords_lst)
            
            yhat = model.predict([document])[0]
            if yhat== 0:
                label = "b√¨nh lu·∫≠n t√≠ch c·ª±c"
            elif yhat== 1:
                label = "b√¨nh lu·∫≠n trung t√≠nh"
            else:
                label = "b√¨nh lu·∫≠n ti√™u c·ª±c"
            st.text("K·∫øt qu·∫£: " + label)
            save_to_database(comment)
            # review = st.selectbox("B·∫°n mu·ªën: ", options = ["B√¨nh lu·∫≠n t√≠ch c·ª±c", "B√¨nh lu·∫≠n trung l·∫≠p", "B√¨nh lu·∫≠n ti√™u c·ª±c"])

        else:
            st.error("Vui l√≤ng nh·∫≠p b√¨nh lu·∫≠n ƒë·ªÉ c√≥ th·ªÉ d·ª± ƒëo√°n")



                
       
                